models:
  - name: llama3
    purpose: general_reasoning
    temperature: 0.2
    max_tokens: 2048
  - name: codellama
    purpose: coding
    temperature: 0.1
    max_tokens: 2048
  - name: qwen2.5
    purpose: summarization
    temperature: 0.2
    max_tokens: 1024
